{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61fee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/12/31\n",
      "ת¼ ����˾ Rev �� ��˽ ���� �� Ա�� �� ���� �ͻ� ���� \n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb7 in position 23: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-01ec6cbe6370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m  \u001b[1;31m#   lines=r.readlines()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinance_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m#print(lines)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb7 in position 23: invalid start byte"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 26 23:07:17 2020\n",
    "\n",
    "@author: wuzix\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#news_file='../建立财务矩阵/raw data/afterMerge/中兴新闻矩阵_with财务删0_afterMerge_5.csv'\n",
    "#finance_file='./Zhongxing_predict_merge_-1.csv'\n",
    "\n",
    "news_file='Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'\n",
    "finance_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\建立财务矩阵\\TechNews_predict_merge_-2.csv'\n",
    "df=pd.read_csv(news_file,error_bad_lines=False)\n",
    "cf=pd.read_csv(finance_file,error_bad_lines=False)\n",
    "news_date=df.iloc[:,0]\n",
    "#df=pd.DataFrame(index=news_date)\n",
    "finance_date=cf.iloc[:,0]\n",
    "\n",
    "print(news_date[0])\n",
    "print(finance_date[0])\n",
    "#differ=set(news_date).difference(finance_date)\n",
    "#print(differ)\n",
    "differ=set(news_date)^set(finance_date)\n",
    "#print(differ)\n",
    "drop=[]\n",
    "drop2=[]\n",
    "drop.append(0)\n",
    "drop2.append(0)\n",
    "drop_date=[]\n",
    "a=[]\n",
    "\n",
    "for i in range(len(news_date)):\n",
    "    if news_date[i] not in differ:\n",
    "        drop.append(i+1)\n",
    "for i in range(len(finance_date)):\n",
    "    if finance_date[i] not in differ:\n",
    "        drop2.append(i+1)\n",
    "\n",
    "'''\n",
    "with open('./中兴新闻矩阵.csv','r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    \n",
    "    #print(lines)\n",
    "    with open('./中兴新闻矩阵_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "       for i in range(len(drop)):\n",
    "            w.write(lines[drop[i]])    \n",
    "\n",
    "'''\n",
    "       \n",
    "            \n",
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ae26c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb7 in position 23: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ffe976f00c2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m  \u001b[1;31m#   lines=r.readlines()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinance_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#print(lines)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb7 in position 23: invalid start byte"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e523835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/12/31\n",
      "2010/2/4\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 26 23:07:17 2020\n",
    "\n",
    "@author: wuzix\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#news_file='../建立财务矩阵/raw data/afterMerge/中兴新闻矩阵_with财务删0_afterMerge_5.csv'\n",
    "#finance_file='./Zhongxing_predict_merge_-1.csv'\n",
    "\n",
    "news_file='Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'\n",
    "finance_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\合并情感维度\\Bi-LSTM\\code\\TechNews_predict_merge_-1_new.csv'\n",
    "df=pd.read_csv(news_file,error_bad_lines=False)\n",
    "cf=pd.read_csv(finance_file,error_bad_lines=False)\n",
    "news_date=df.iloc[:,0]\n",
    "#df=pd.DataFrame(index=news_date)\n",
    "finance_date=cf.iloc[:,0]\n",
    "\n",
    "print(news_date[0])\n",
    "print(finance_date[0])\n",
    "#differ=set(news_date).difference(finance_date)\n",
    "#print(differ)\n",
    "differ=set(news_date)^set(finance_date)\n",
    "#print(differ)\n",
    "drop=[]\n",
    "drop2=[]\n",
    "drop.append(0)\n",
    "drop2.append(0)\n",
    "drop_date=[]\n",
    "a=[]\n",
    "\n",
    "for i in range(len(news_date)):\n",
    "    if news_date[i] not in differ:\n",
    "        drop.append(i+1)\n",
    "for i in range(len(finance_date)):\n",
    "    if finance_date[i] not in differ:\n",
    "        drop2.append(i+1)\n",
    "\n",
    "'''\n",
    "with open('./中兴新闻矩阵.csv','r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    \n",
    "    #print(lines)\n",
    "    with open('./中兴新闻矩阵_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "       for i in range(len(drop)):\n",
    "            w.write(lines[drop[i]])    \n",
    "\n",
    "'''\n",
    "       \n",
    "            \n",
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01674abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/2/4\n",
      "2010/2/4\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 50-51: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-112100fda8c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m  \u001b[1;31m#   lines=r.readlines()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinance_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m#print(lines)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 50-51: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 26 23:07:17 2020\n",
    "\n",
    "@author: wuzix\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#news_file='../建立财务矩阵/raw data/afterMerge/中兴新闻矩阵_with财务删0_afterMerge_5.csv'\n",
    "#finance_file='./Zhongxing_predict_merge_-1.csv'\n",
    "\n",
    "news_file='Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'\n",
    "finance_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\合并情感维度\\Bi-LSTM\\code\\TechNews_predict_merge_-1_new.csv'\n",
    "df=pd.read_csv(news_file,error_bad_lines=False)\n",
    "cf=pd.read_csv(finance_file,error_bad_lines=False)\n",
    "news_date=df.iloc[:,0]\n",
    "#df=pd.DataFrame(index=news_date)\n",
    "finance_date=cf.iloc[:,0]\n",
    "\n",
    "print(news_date[0])\n",
    "print(finance_date[0])\n",
    "#differ=set(news_date).difference(finance_date)\n",
    "#print(differ)\n",
    "differ=set(news_date)^set(finance_date)\n",
    "#print(differ)\n",
    "drop=[]\n",
    "drop2=[]\n",
    "drop.append(0)\n",
    "drop2.append(0)\n",
    "drop_date=[]\n",
    "a=[]\n",
    "\n",
    "for i in range(len(news_date)):\n",
    "    if news_date[i] not in differ:\n",
    "        drop.append(i+1)\n",
    "for i in range(len(finance_date)):\n",
    "    if finance_date[i] not in differ:\n",
    "        drop2.append(i+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa3475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019/12/31\n",
      "1       2019/12/30\n",
      "2       2019/12/27\n",
      "3       2019/12/26\n",
      "4       2019/12/25\n",
      "           ...    \n",
      "1723     2010/2/25\n",
      "1724     2010/2/24\n",
      "1725      2010/2/9\n",
      "1726      2010/2/5\n",
      "1727      2010/2/4\n",
      "Name: date, Length: 1728, dtype: object\n",
      "0        2010/2/4\n",
      "1        2010/2/5\n",
      "2        2010/2/9\n",
      "3       2010/2/18\n",
      "4       2010/2/21\n",
      "          ...    \n",
      "9420     2020/3/2\n",
      "9421     2020/3/2\n",
      "9422     2020/3/2\n",
      "9423     2020/3/2\n",
      "9424     2020/3/2\n",
      "Name: Date, Length: 9425, dtype: object\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 50-51: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-223d5c2a38c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m  \u001b[1;31m#   lines=r.readlines()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinance_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;31m#print(lines)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 50-51: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 26 23:07:17 2020\n",
    "\n",
    "@author: wuzix\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#news_file='../建立财务矩阵/raw data/afterMerge/中兴新闻矩阵_with财务删0_afterMerge_5.csv'\n",
    "#finance_file='./Zhongxing_predict_merge_-1.csv'\n",
    "\n",
    "news_file='.\\Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'\n",
    "finance_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\合并情感维度\\Bi-LSTM\\code\\TechNews_predict_merge_-1_new1.csv'\n",
    "df=pd.read_csv(news_file,error_bad_lines=False)\n",
    "cf=pd.read_csv(finance_file,error_bad_lines=False)\n",
    "news_date=df.iloc[:,0]\n",
    "#df=pd.DataFrame(index=news_date)\n",
    "finance_date=cf.iloc[:,0]\n",
    "\n",
    "print(news_date)\n",
    "print(finance_date)\n",
    "differ=set(news_date).difference(finance_date)\n",
    "#print(differ)\n",
    "#differ=set(news_date)^set(finance_date)\n",
    "#print(differ)\n",
    "drop=[]\n",
    "drop2=[]\n",
    "drop.append(0)\n",
    "drop2.append(0)\n",
    "drop_date=[]\n",
    "a=[]\n",
    "for i in range(len(news_date)):\n",
    "    if news_date[i] not in differ:\n",
    "        drop.append(i+1)\n",
    "for i in range(len(finance_date)):\n",
    "    if finance_date[i] not in differ:\n",
    "        drop2.append(i+1)\n",
    "\n",
    "'''\n",
    "with open('./中兴新闻矩阵.csv','r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    \n",
    "    #print(lines)\n",
    "    with open('./中兴新闻矩阵_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "       for i in range(len(drop)):\n",
    "            w.write(lines[drop[i]])    \n",
    "\n",
    "'''\n",
    "       \n",
    "            \n",
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c120b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91f96a39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7724844ac755>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m  \u001b[1;31m#   lines=r.readlines()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefaultencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinance_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reload' is not defined"
     ]
    }
   ],
   "source": [
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15268b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019/12/31\n",
      "1       2019/12/30\n",
      "2       2019/12/27\n",
      "3       2019/12/26\n",
      "4       2019/12/25\n",
      "           ...    \n",
      "1723     2010/2/25\n",
      "1724     2010/2/24\n",
      "1725      2010/2/9\n",
      "1726      2010/2/5\n",
      "1727      2010/2/4\n",
      "Name: date, Length: 1728, dtype: object\n",
      "0        2010/2/4\n",
      "1        2010/2/5\n",
      "2        2010/2/9\n",
      "3       2010/2/18\n",
      "4       2010/2/21\n",
      "          ...    \n",
      "9420     2020/3/2\n",
      "9421     2020/3/2\n",
      "9422     2020/3/2\n",
      "9423     2020/3/2\n",
      "9424     2020/3/2\n",
      "Name: Date, Length: 9425, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 26 23:07:17 2020\n",
    "\n",
    "@author: wuzix\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#news_file='../建立财务矩阵/raw data/afterMerge/中兴新闻矩阵_with财务删0_afterMerge_5.csv'\n",
    "#finance_file='./Zhongxing_predict_merge_-1.csv'\n",
    "\n",
    "news_file='.\\Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'\n",
    "finance_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\合并情感维度\\Bi-LSTM\\code\\merge合并预测结果.csv'\n",
    "df=pd.read_csv(news_file,error_bad_lines=False)\n",
    "cf=pd.read_csv(finance_file,error_bad_lines=False)\n",
    "news_date=df.iloc[:,0]\n",
    "#df=pd.DataFrame(index=news_date)\n",
    "finance_date=cf.iloc[:,0]\n",
    "\n",
    "print(news_date)\n",
    "print(finance_date)\n",
    "differ=set(news_date).difference(finance_date)\n",
    "#print(differ)\n",
    "#differ=set(news_date)^set(finance_date)\n",
    "#print(differ)\n",
    "drop=[]\n",
    "drop2=[]\n",
    "drop.append(0)\n",
    "drop2.append(0)\n",
    "drop_date=[]\n",
    "a=[]\n",
    "for i in range(len(news_date)):\n",
    "    if news_date[i] not in differ:\n",
    "        drop.append(i+1)\n",
    "for i in range(len(finance_date)):\n",
    "    if finance_date[i] not in differ:\n",
    "        drop2.append(i+1)\n",
    "\n",
    "'''\n",
    "with open('./中兴新闻矩阵.csv','r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    \n",
    "    #print(lines)\n",
    "    with open('./中兴新闻矩阵_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "       for i in range(len(drop)):\n",
    "            w.write(lines[drop[i]])    \n",
    "\n",
    "'''\n",
    "       \n",
    "            \n",
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28b4b92",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\股票预测测试\\\\stock-prediction-main\\\\代码\\\\个股走势预测\\\\建立财务矩阵\\\\合并出新闻矩阵\\\\Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-74e6dd9877cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mnews_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\建立财务矩阵\\合并出新闻矩阵\\Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mfinance_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\建立财务矩阵\\合并出新闻矩阵\\中兴新闻矩阵_3.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinance_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mnews_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m         )\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\stock\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\股票预测测试\\\\stock-prediction-main\\\\代码\\\\个股走势预测\\\\建立财务矩阵\\\\合并出新闻矩阵\\\\Zhongxing财务_删0_label0.01_forVisual_afterMerge.csv'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 26 23:07:17 2020\n",
    "\n",
    "@author: wuzix\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#news_file='../建立财务矩阵/raw data/afterMerge/中兴新闻矩阵_with财务删0_afterMerge_5.csv'\n",
    "#finance_file='./Zhongxing_predict_merge_-1.csv'\n",
    "\n",
    "news_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\建立财务矩阵\\合并出新闻矩阵\\Zhongxing财务_删0_label0.01_zscore.csv'\n",
    "finance_file='F:\\股票预测测试\\stock-prediction-main\\代码\\个股走势预测\\建立财务矩阵\\合并出新闻矩阵\\中兴新闻矩阵_3.csv'\n",
    "df=pd.read_csv(news_file,error_bad_lines=False)\n",
    "cf=pd.read_csv(finance_file,error_bad_lines=False)\n",
    "news_date=df.iloc[:,0]\n",
    "#df=pd.DataFrame(index=news_date)\n",
    "finance_date=cf.iloc[:,0]\n",
    "\n",
    "print(news_date)\n",
    "print(finance_date)\n",
    "differ=set(news_date).difference(finance_date)\n",
    "#print(differ)\n",
    "#differ=set(news_date)^set(finance_date)\n",
    "#print(differ)\n",
    "drop=[]\n",
    "drop2=[]\n",
    "drop.append(0)\n",
    "drop2.append(0)\n",
    "drop_date=[]\n",
    "a=[]\n",
    "for i in range(len(news_date)):\n",
    "    if news_date[i] not in differ:\n",
    "        drop.append(i+1)\n",
    "for i in range(len(finance_date)):\n",
    "    if finance_date[i] not in differ:\n",
    "        drop2.append(i+1)\n",
    "\n",
    "'''\n",
    "with open('./中兴新闻矩阵.csv','r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    \n",
    "    #print(lines)\n",
    "    with open('./中兴新闻矩阵_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "       for i in range(len(drop)):\n",
    "            w.write(lines[drop[i]])    \n",
    "\n",
    "'''\n",
    "       \n",
    "            \n",
    "#with open('./Zhongxing_predict_merge_-1.csv','r',encoding='utf-8') as r:\n",
    " #   lines=r.readlines()\n",
    "with open(finance_file,'r',encoding='utf-8') as r:\n",
    "    lines=r.readlines()\n",
    "    #print(lines)\n",
    "    # with open('./afterMerge/Zhongxing_predict_mergeNews-1_with财务删0_afterMerge.csv','w',encoding='utf-8') as w:\n",
    "    #    for i in range(len(drop2)):\n",
    "    #         w.write(lines[drop2[i]])\n",
    "    with open(news_file,'w',encoding='utf-8') as w:\n",
    "           for i in range(len(drop2)):\n",
    "                w.write(lines[drop2[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae8adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stock)",
   "language": "python",
   "name": "stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
